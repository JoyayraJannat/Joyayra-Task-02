# -*- coding: utf-8 -*-
"""Task 02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RJ9C5i9Nn-rxXszJWD464ApBxisPCGCE

**1. Introduction**

This project aims to model and evaluate a business or manufacturing process using Python. It involves importing and cleaning process data, simulating task execution with resource constraints, and calculating key performance indicators (KPIs) like throughput time, cycle time, and resource utilization. By identifying bottlenecks and inefficiencies, the analysis will recommend optimizations for improved throughput and efficiency. Visualizations, including flow diagrams and performance charts, will help illustrate the process and highlight areas for improvement.

**Prelimeneries**

Load the various packages required to complete the work and set up the matplotlib plotting environment.
"""

import pandas as pd
import simpy
import matplotlib.pyplot as plt

"""**2. Data Import and Cleaning**

o Import process data from a CSV file.

o Clean the data to handle missing values, duplicates, and outliers.
"""

file_path = '/content/Joyayra_Jannat_Process_Modeling_and_Performance_Evaluation.csv'

try:
    # Import the data
    df = pd.read_csv(file_path)

    # Display the first few rows of the dataframe
    print("Original Data:")
    print(df.head())

    # Handle missing values (replace with mean, median or drop rows/columns)
    # Example: Fill missing numerical values with the mean
    for col in df.select_dtypes(include=['number']):
      df[col] = df[col].fillna(df[col].mean())
    # Example: Drop rows with any missing values
    # df = df.dropna()

    # Remove duplicate rows
    df = df.drop_duplicates()

    # Identify outliers (example: using IQR)
    # For numerical features
    for col in df.select_dtypes(include=['number']):
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]

    # Display the cleaned data
    print("\nCleaned Data:")
    print(df.head())


except FileNotFoundError:
    print(f"Error: File '{file_path}' not found.")
except pd.errors.ParserError:
    print(f"Error: Could not parse the CSV file '{file_path}'. Please check the file format.")
except Exception as e:
    print(f"An unexpected error occurred: {e}")

"""**3. Process Modeling**

o Model each task in the process with dependencies and assigned resources.

o Simulate the execution of the process, considering resource constraints and task
durations.
"""

# Create SimPy environment (moved to the top)
env = simpy.Environment()

# Define resources
resources = {
    'Resource1': simpy.Resource(env, capacity=2),  # Example: 2 units of Resource1
    'Resource2': simpy.Resource(env, capacity=1)   # Example: 1 unit of Resource2
}

# Define tasks with dependencies and resource requirements
def task1(env, name, resource1, resource2):
    with resource1.request() as req1, resource2.request() as req2:
        yield req1
        yield req2
        print(f'{name} started at {env.now}')
        yield env.timeout(5)  # Task duration: 5 time units
        print(f'{name} finished at {env.now}')

def task2(env, name, resource1):
    with resource1.request() as req:
        yield req
        print(f'{name} started at {env.now}')
        yield env.timeout(3)  # Task duration: 3 time units
        print(f'{name} finished at {env.now}')

# Define processes for each task
process1 = env.process(task1(env, 'Task 1', resources['Resource1'], resources['Resource2']))
process2 = env.process(task2(env, 'Task 2', resources['Resource1']))

# Run the simulation
env.run(until=10)  # Simulate for 10 time units

"""**4. Performance Evaluation**

o Calculate key performance indicators (KPIs) such as throughput time, cycle time, and resource utilization.

o Identify bottlenecks in the process where delays or inefficiencies are observed.
"""

# Create SimPy environment
env = simpy.Environment()

# Define resources
resources = {
    'Resource1': simpy.Resource(env, capacity=2),
    'Resource2': simpy.Resource(env, capacity=1)
}

# Data collection lists
task_data = []

# Define tasks with dependencies and resource requirements
def task1(env, name, resource1, resource2):
    start_time = env.now
    with resource1.request() as req1, resource2.request() as req2:
        yield req1
        yield req2
        #print(f'{name} started at {env.now}') #Remove for clarity
        yield env.timeout(5)
        #print(f'{name} finished at {env.now}') #Remove for clarity
    end_time = env.now
    task_data.append([name, start_time, end_time])

def task2(env, name, resource1):
    start_time = env.now
    with resource1.request() as req:
        yield req
       # print(f'{name} started at {env.now}') #Remove for clarity
        yield env.timeout(3)
        #print(f'{name} finished at {env.now}') #Remove for clarity
    end_time = env.now
    task_data.append([name, start_time, end_time])

# Define processes for each task
process1 = env.process(task1(env, 'Task 1', resources['Resource1'], resources['Resource2']))
process2 = env.process(task2(env, 'Task 2', resources['Resource1']))

# Run the simulation
env.run(until=10)

# Create a Pandas DataFrame from the collected data
df_tasks = pd.DataFrame(task_data, columns=['Task', 'Start_Time', 'End_Time'])

# Calculate Throughput Time
df_tasks['Throughput_Time'] = df_tasks['End_Time'] - df_tasks['Start_Time']

# Calculate Cycle Time (similar to Throughput Time in this case)
df_tasks['Cycle_Time'] = df_tasks['Throughput_Time']

# Calculate Resource Utilization
resource1_utilization = resources['Resource1'].count / env.now
resource2_utilization = resources['Resource2'].count / env.now

# Display KPIs
print("KPIs:")
print(df_tasks[['Task', 'Throughput_Time', 'Cycle_Time']]) # Show only relevant columns
print("\nResource1 Utilization:", resource1_utilization)
print("Resource2 Utilization:", resource2_utilization)

# Identify Bottlenecks (example logic)
if resource1_utilization > 0.8:
    print("\nPotential Bottleneck: Resource1 utilization is high.")
if resource2_utilization > 0.8:
    print("Potential Bottleneck: Resource2 utilization is high.")
if df_tasks['Throughput_Time'].max() > 8: #Example threshold
    print("Potential Bottleneck: Some tasks have long throughput times.")

"""**5. Optimization Recommendations**

o Analyze the process performance and suggest changes to improve throughput and
efficiency.

o Recommend adjustments to resource allocation or task sequencing to minimize delays.
"""

# Analyze KPIs and identify bottlenecks
print("\nOptimization Recommendations:")

# Resource utilization analysis
if resource1_utilization > 0.8:
    print(" - Increase the capacity of Resource1.  Consider adding more units or optimizing its usage.")
    print("     - Explore task reassignment or task splitting to reduce dependency on Resource 1.")
if resource2_utilization > 0.8:
    print(" - Increase the capacity of Resource2 or improve its efficiency.")

# Throughput time analysis
max_throughput_time = df_tasks['Throughput_Time'].max()
if max_throughput_time > 8: #Example Threshold - adjust as needed
    print(" - Tasks with high throughput times may indicate bottlenecks.")
    slow_tasks = df_tasks[df_tasks['Throughput_Time'] > 8]['Task'] #identify slow tasks
    print(f"   - Focus on improving the efficiency of these tasks: {slow_tasks.tolist()}")
    print("     - Investigate potential delays or dependencies within these tasks.")

# Task Sequencing
print(" - Analyze task dependencies.  Is there a more efficient order in which tasks could be performed?")
print("     - Consider parallel processing where possible to minimize idle times.")


# Further Analysis and Recommendations:
print("\nFurther Considerations:")
print(" - Gather more detailed data for a more comprehensive analysis (e.g., task-specific details).")
print(" - Experiment with different resource allocation strategies and task sequences using the simulation model.")
print(" - Consider using queuing theory to model task waiting times and resource contention more accurately.")
print(" - Visualize the process flow and resource utilization to easily identify bottlenecks (e.g., Gantt chart).")

"""**6. Visualization**

o Create:

▪ A flow diagram of the process showing tasks and dependencies.

▪ A bar chart to compare resource utilization across tasks.

▪ A line chart to visualize throughput and cycle time over time.
"""

# Resource Utilization Bar Chart
resource_utilization = {
    'Resource1': resource1_utilization,
    'Resource2': resource2_utilization
}
resources_names = list(resource_utilization.keys())
utilization_values = list(resource_utilization.values())

plt.figure(figsize=(8, 6))
plt.bar(resources_names, utilization_values, color=['skyblue', 'lightcoral'])
plt.xlabel("Resources")
plt.ylabel("Utilization")
plt.title("Resource Utilization")
plt.ylim(0, 1)  # Set y-axis limit to 0-1 for utilization
plt.show()


# Throughput and Cycle Time Line Chart
plt.figure(figsize=(10, 6))
plt.plot(df_tasks['End_Time'], df_tasks['Throughput_Time'], label='Throughput Time', marker='o', linestyle='-')
plt.plot(df_tasks['End_Time'], df_tasks['Cycle_Time'], label='Cycle Time', marker='x', linestyle='--')
plt.xlabel("Time")
plt.ylabel("Time (units)")
plt.title("Throughput and Cycle Time over Time")
plt.legend()
plt.grid(True)
plt.show()

# Note: Flow diagram creation requires a dedicated library
# like graphviz or a similar visualization tool. An example
# using text-based representation is given below.


print("\nProcess Flow Diagram (Text-based representation):")
print("Task 1 (Resource1, Resource2) --> Task 2 (Resource1)")